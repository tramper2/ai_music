{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_multitrack_musicvae.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMH/gkRuzMG3GvVsFHMN1AV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/ai_music/blob/main/section_4/01_multitrack_musicvae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPkdg9jTjkTd"
      },
      "source": [
        "# Music VAE에 의한 작곡\n",
        "[Music VAE]를 통해 여러 트랙으로 이루어진 곡을 생성합니다.  \n",
        "생성에는 시간이 걸리기 때문에, 「편집」→「노트북의 설정」→「하드웨어 액셀러레이터」로「GPU」를 선택해 둡시다.  \n",
        "이 노트북의 코드는 아래의 링크처의 코드를 참고하고 있습니다.  \n",
        "https://g.co/magenta/musicvae-colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPKARfZNZ_EA"
      },
      "source": [
        "## 라이브러리 설치 및 모델 다운로드\n",
        "Magenta와 함께 음악 생성용 라이브러리 pyFluid Synth, MIDI 데이터를 처리하기 위한 pretty_midi 등을 설치합니다.  \n",
        "또한, MusicVAE 모델을 다운로드 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRTOCXhK9YAM"
      },
      "source": [
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip install -qU pyfluidsynth pretty_midi\n",
        "!pip install -qU magenta\n",
        "\n",
        "!gsutil -q -m cp gs://download.magenta.tensorflow.org/models/music_vae/multitrack/* /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5-xG4QVx1iK"
      },
      "source": [
        "## 라이브러리의 도입\n",
        "Magenta의 필요한 기능과 NumPy 등의 라이브러리를 도입합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuBbvFkNssM3"
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "import magenta.music as mm\n",
        "from magenta.models.music_vae import configs\n",
        "from magenta.models.music_vae.trained_model import TrainedModel\n",
        "from magenta.music.sequences_lib import concatenate_sequences\n",
        "\n",
        "import note_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XAYVxmpyLQb"
      },
      "source": [
        "## 각 설정값 \n",
        "곡의 생성에 관한 각 값을 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD3DbsM_rBP5"
      },
      "source": [
        "BATCH_SIZE = 4  # 一度に扱うデータ数\n",
        "Z_SIZE = 512  # 潜在変数の数\n",
        "TOTAL_STEPS = 512  # コードのベクトル化に使用\n",
        "CHORD_DEPTH = 49  # コードのベクトル化に使用\n",
        "SEQ_TIME = 2.0  # 各NoteSequenceの長さ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDC_l0Guz-go"
      },
      "source": [
        "## 함수의 설정\n",
        '자주 실시하는 처리를 함수에 정리해 둡니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91UHtM2lrNvM"
      },
      "source": [
        "def trim(seqs, seq_time=SEQ_TIME):  # NoteSequenceの長さを揃える\n",
        "    for i in range(len(seqs)):\n",
        "        seqs[i] = mm.extract_subsequence(seqs[i], 0.0, seq_time)\n",
        "        seqs[i].total_time = seq_time\n",
        "\n",
        "def encode_chord(chord):  # コードの文字列をベクトルに変換\n",
        "    index = mm.TriadChordOneHotEncoding().encode_event(chord)\n",
        "    encoded = np.zeros([TOTAL_STEPS, CHORD_DEPTH])\n",
        "    encoded[0,0] = 1.0\n",
        "    encoded[1:,index] = 1.0\n",
        "    return encoded\n",
        "\n",
        "def set_instruments(note_sequences):  # 楽器の調整\n",
        "    for i in range(len(note_sequences)):\n",
        "        for note in note_sequences[i].notes:\n",
        "            if note.is_drum:\n",
        "                note.instrument = 9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4cnU3U75KJQ"
      },
      "source": [
        "## Conditional이 아닌 모델\n",
        "Conditional이 아닌 일반 VAE의 학습완료 모델을 체크 포인트로 읽습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w77rMbln5Q5K"
      },
      "source": [
        "config = configs.CONFIG_MAP[\"hier-multiperf_vel_1bar_med\"]\n",
        "model = TrainedModel(\n",
        "    config,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    checkpoint_dir_or_path=\"/content/model_fb256.ckpt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1le8iM0PgLt"
      },
      "source": [
        "모델로부터 랜덤하게 음성을 샘플링 합니다.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBxRZjWO5VMH"
      },
      "source": [
        "temperature = 0.2\n",
        "seqs = model.sample(n=BATCH_SIZE, length=TOTAL_STEPS, temperature=temperature)\n",
        "\n",
        "trim(seqs)\n",
        "for seq in seqs:\n",
        "    mm.play_sequence(seq, synth=mm.fluidsynth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjxglQSRP2Ef"
      },
      "source": [
        "잠재 변수에서 곡을 생성합니다.  \n",
        "연속적으로 변화하는 잠재변수를 디코딩하여 연결함으로써 곡을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWGL9Rn36E85"
      },
      "source": [
        "num_bars = 32\n",
        "temperature = 0.2\n",
        "\n",
        "z1 = np.random.normal(size=[Z_SIZE])\n",
        "z2 = np.random.normal(size=[Z_SIZE])\n",
        "z = np.array([z1+z2*t for t in np.linspace(0, 1, num_bars)])  # z1とz2の間を線形補間\n",
        "\n",
        "seqs = model.decode(length=TOTAL_STEPS, z=z, temperature=temperature)\n",
        "\n",
        "trim(seqs)\n",
        "set_instruments(seqs)\n",
        "seq = concatenate_sequences(seqs)\n",
        "\n",
        "mm.plot_sequence(seq)\n",
        "mm.play_sequence(seq, synth=mm.fluidsynth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y0BXztnDHep"
      },
      "source": [
        "`노트Sequence`를 MIDI 데이터로 변환하여 저장하고 다운로드합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V2HpDk9DHe2"
      },
      "source": [
        "note_seq.sequence_proto_to_midi_file(seq, \"unconditional_vae.mid\")  #MIDI　データに変換し保存\n",
        "files.download(\"unconditional_vae.mid\")  # ダウンロード"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJHzFw6Z0YRU"
      },
      "source": [
        "## Conditional한 모델\n",
        "코드를 라벨로 한 Conditional VAE 모델을 읽습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3L9yw9Lqh8r"
      },
      "source": [
        "config = configs.CONFIG_MAP[\"hier-multiperf_vel_1bar_med_chords\"]\n",
        "model = TrainedModel(\n",
        "    config,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    checkpoint_dir_or_path=\"/content/model_chords_fb64.ckpt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qlih9njq1f4S"
      },
      "source": [
        "코드를 라벨로 입력하고 모델에서 랜덤하게 음성을 샘플링합니다.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziuRHiwyrUq4"
      },
      "source": [
        "chord = \"C\"\n",
        "temperature = 0.2\n",
        "\n",
        "seqs = model.sample(n=BATCH_SIZE, length=TOTAL_STEPS, temperature=temperature,\n",
        "                    c_input=encode_chord(chord))\n",
        "\n",
        "for seq in seqs:\n",
        "    mm.play_sequence(seq, synth=mm.fluidsynth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e_Xw9ioSCtn"
      },
      "source": [
       "잠재변수에서 곡을 디코딩할 때 코드를 라벨로 입력합니다.  \n",
        "이를 통해, 해당 코드를 기반으로 한 곡의 노트Seqence를 생성할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LxRc33frkw3"
      },
      "source": [
        "chord_1 = \"C\"\n",
        "chord_2 = \"Caug\"\n",
        "chord_3 = \"Am\"\n",
        "chord_4 = \"E\"\n",
        "chords = [chord_1, chord_2, chord_3, chord_4]\n",
        "\n",
        "temperature = 0.2\n",
        "z = np.random.normal(size=[1, Z_SIZE])\n",
        "seqs = [\n",
        "    model.decode(length=TOTAL_STEPS,\n",
        "                 z=z,\n",
        "                 temperature=temperature,\n",
        "                 c_input=encode_chord(c))[0]\n",
        "    for c in chords\n",
        "]\n",
        "\n",
        "trim(seqs)\n",
        "set_instruments(seqs)\n",
        "seq = concatenate_sequences(seqs)\n",
        "\n",
        "mm.plot_sequence(seq)\n",
        "mm.play_sequence(seq, synth=mm.fluidsynth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJDb3yWxTThS"
      },
      "source": [
        "잠재변수와 베이스가 되는 코드진행에서 곡을 생성합니다.  \n",
        "연속적으로 변화하는 잠재변수를 코드와 함께 디코딩하여 연결함으로써 곡을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL3woZZywivE"
      },
      "source": [
        "chord_1 = \"Dm\"\n",
        "chord_2 = \"F\"\n",
        "chord_3 = \"Am\"\n",
        "chord_4 = \"G\"\n",
        "chords = [chord_1, chord_2, chord_3, chord_4]\n",
        "\n",
        "num_bars = 32\n",
        "temperature = 0.2\n",
        "\n",
        "z1 = np.random.normal(size=[Z_SIZE])\n",
        "z2 = np.random.normal(size=[Z_SIZE])\n",
        "z = np.array([z1+z2*t for t in np.linspace(0, 1, num_bars)])  # z1とz2の間を線形補間\n",
        "\n",
        "seqs = [\n",
        "    model.decode(\n",
        "        length=TOTAL_STEPS,\n",
        "        z=z[i:i+1, :],\n",
        "        temperature=temperature,\n",
        "        c_input=encode_chord(chords[i%4])\n",
        "        )[0]\n",
        "    for i in range(num_bars)\n",
        "]\n",
        "\n",
        "trim(seqs)\n",
        "set_instruments(seqs)\n",
        "seq = concatenate_sequences(seqs)\n",
        "\n",
        "mm.plot_sequence(seq)\n",
        "mm.play_sequence(seq, synth=mm.fluidsynth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhtRBNNf05CA"
      },
      "source": [
       " 노트Sequence 를 MIDI 데이터로 변환하여 저장하고 다운로드합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcmmAToP4WE3"
      },
      "source": [
        "note_seq.sequence_proto_to_midi_file(seq, \"conditional_vae.mid\")  #MIDI　データに変換し保存\n",
        "files.download(\"conditional_vae.mid\")  # ダウンロード"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
